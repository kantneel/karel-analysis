{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json \n",
    "f = open('report-val.json')\n",
    "overall_stats = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 96)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "USE_VAL = False\n",
    "NUM_RECORDS = None\n",
    "\n",
    "if USE_VAL:\n",
    "    data = np.loadtxt('val-data.csv', delimiter=',').astype(float)\n",
    "    labels = np.loadtxt('val-labels.csv', delimiter=',')\n",
    "    NUM_RECORDS = 2500\n",
    "else:\n",
    "    data = np.concatenate((np.loadtxt('train-data1.csv', delimiter=','), \n",
    "                            np.loadtxt('train-data2.csv', delimiter=','))).astype(float)\n",
    "    print(data.shape)\n",
    "    labels = np.loadtxt('train-labels.csv', delimiter=',')[:60000]\n",
    "    print(labels.shape)\n",
    "    NUM_RECORDS = 60000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore different ways to canonicalize the I/O\n",
    " 1. Data is coming in as (2500, 78) -> first reshape to (2500, 6, 13)\n",
    " 2. Sort rows based on a column value\n",
    " 3. reshape back to (2500, 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79643750000000002, 0.79622916666666665, 0.79597916666666668, 0.7963958333333333, 0.79668749999999999, 0.79693749999999997, 0.79658333333333331, 0.80189583333333336, 0.79785416666666664, 0.79610416666666661, 0.79549999999999998, 0.79956249999999995, 0.79777083333333332]\n",
      "**********************\n",
      "[0.79208333333333336, 0.79108333333333336, 0.79183333333333328, 0.79100000000000004, 0.79091666666666671, 0.79116666666666668, 0.79216666666666669, 0.79458333333333331, 0.79033333333333333, 0.79025000000000001, 0.78983333333333339, 0.79300000000000004, 0.79574999999999996]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "io_data = data[:, 18:]\n",
    "reshaped_data = io_data.reshape((NUM_RECORDS, 6, 13))\n",
    "\n",
    "val1, train1 = [], []\n",
    "VAL_CUTOFF = int(NUM_RECORDS * 0.8)\n",
    "\n",
    "for i in range(13):  \n",
    "    fresh_data = np.zeros((NUM_RECORDS, 78))\n",
    "    for t in range(NUM_RECORDS): # t for trial\n",
    "        rows = reshaped_data[t]\n",
    "        sorted_rows = rows[rows[:,i].argsort()]\n",
    "        fresh_data[t] = sorted_rows.reshape(78)\n",
    "    \n",
    "    #print(data[:, :18].shape)\n",
    "    #print(fresh_data.shape)\n",
    "    reformatted_data = np.concatenate((data[:, :18], fresh_data), axis=1)\n",
    "    for c in range(96):\n",
    "        reformatted_data /= np.max(np.abs(reformatted_data[:,c])) + 1e-4\n",
    "        reformatted_data[:,c] -= np.mean(reformatted_data[:,c])\n",
    "    \n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(reformatted_data[:VAL_CUTOFF], labels[:VAL_CUTOFF])\n",
    "    train1.append(log_reg.score(reformatted_data[:VAL_CUTOFF], labels[:VAL_CUTOFF]))\n",
    "    \n",
    "\n",
    "    val1.append(log_reg.score(reformatted_data[VAL_CUTOFF:], labels[VAL_CUTOFF:]))\n",
    "\n",
    "print(train1)\n",
    "print(\"**********************\")\n",
    "print(val1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# logistic regression isn't super impressive ~82% accuracy. \n",
    "# let's try basic neural network instead\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, activation='relu', input_shape=(96,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "io_data = data[:, 18:]\n",
    "reshaped_data = io_data.reshape((2500, 6, 13))\n",
    "\n",
    "# val1, val2, train1, train2 = [], [], [], []\n",
    "\n",
    "for i in range(13):  \n",
    "    fresh_data = np.zeros((2500, 78))\n",
    "    for t in range(2500): # t for trial\n",
    "        rows = reshaped_data[t]\n",
    "        sorted_rows = rows[rows[:,i].argsort()]\n",
    "        fresh_data[t] = sorted_rows.reshape(78)\n",
    "    \n",
    "    #print(data[:, :18].shape)\n",
    "    #print(fresh_data.shape)\n",
    "    reformatted_data = np.concatenate((data[:, :18], fresh_data), axis=1)\n",
    "    for c in range(96):\n",
    "        reformatted_data /= np.max(np.abs(reformatted_data[:,c])) + 1e-4\n",
    "        reformatted_data[:,c] -= np.mean(reformatted_data[:,c])\n",
    "       \n",
    "\n",
    "    model.fit(reformatted_data[:2000], labels[:2000], \n",
    "             batch_size=16, nb_epoch=5, verbose=1)\n",
    "    print(model.evaluate(reformatted_data[2000:], labels[2000:], verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
